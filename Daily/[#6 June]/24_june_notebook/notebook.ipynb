{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Spell Correction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing Textual Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [],
   "source": [
    "import neattext as nt\n",
    "import pandas as pd\n",
    "import neattext.functions as nfx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extracting texts only"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "data": {
      "text/plain": "             author claps  reading_time  \\\n0        Justin Lee  8.3K            11   \n1       Conor Dewey  1.4K             7   \n2  William Koehrsen  2.8K            11   \n3      Gant Laborde  1.3K             7   \n4  Emmanuel Ameisen   935            11   \n\n                                                link  \\\n0  https://medium.com/swlh/chatbots-were-the-next...   \n1  https://towardsdatascience.com/python-for-data...   \n2  https://towardsdatascience.com/automated-featu...   \n3  https://medium.freecodecamp.org/machine-learni...   \n4  https://blog.insightdatascience.com/reinforcem...   \n\n                                               title  \\\n0  Chatbots were the next big thing: what happene...   \n1  Python for Data Science: 8 Concepts You May Ha...   \n2  Automated Feature Engineering in Python – Towa...   \n3  Machine Learning: how to go from Zero to Hero ...   \n4  Reinforcement Learning from scratch – Insight ...   \n\n                                                text  \n0  Oh, how the headlines blared:\\nChatbots were T...  \n1  If you’ve ever found yourself looking up the s...  \n2  Machine learning is increasingly moving from h...  \n3  If your understanding of A.I. and Machine Lear...  \n4  Want to learn about applied Artificial Intelli...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>claps</th>\n      <th>reading_time</th>\n      <th>link</th>\n      <th>title</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Justin Lee</td>\n      <td>8.3K</td>\n      <td>11</td>\n      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n      <td>Chatbots were the next big thing: what happene...</td>\n      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Conor Dewey</td>\n      <td>1.4K</td>\n      <td>7</td>\n      <td>https://towardsdatascience.com/python-for-data...</td>\n      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n      <td>If you’ve ever found yourself looking up the s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>William Koehrsen</td>\n      <td>2.8K</td>\n      <td>11</td>\n      <td>https://towardsdatascience.com/automated-featu...</td>\n      <td>Automated Feature Engineering in Python – Towa...</td>\n      <td>Machine learning is increasingly moving from h...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Gant Laborde</td>\n      <td>1.3K</td>\n      <td>7</td>\n      <td>https://medium.freecodecamp.org/machine-learni...</td>\n      <td>Machine Learning: how to go from Zero to Hero ...</td>\n      <td>If your understanding of A.I. and Machine Lear...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Emmanuel Ameisen</td>\n      <td>935</td>\n      <td>11</td>\n      <td>https://blog.insightdatascience.com/reinforcem...</td>\n      <td>Reinforcement Learning from scratch – Insight ...</td>\n      <td>Want to learn about applied Artificial Intelli...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/articles.csv\")\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "data = data[\"text\"].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "data": {
      "text/plain": "str"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "texts = \"\".join(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "data": {
      "text/plain": "'Oh, how the headlines blared:\\nChatbots were The Next Big Thing.\\nOur hopes were sky high. Bright-eyed'"
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oh,', 'how', 'the', 'headlines', 'blared:', 'Chatbots', 'were', 'The', 'Next', 'Big']\n"
     ]
    }
   ],
   "source": [
    "check = texts.split()\n",
    "print(check[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "cleaned_text = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "for i in check:\n",
    "    cleaned_text += nfx.clean_text(i, stopwords=False, puncts=True, urls=True, numbers=True, special_char=True,\n",
    "                                  phone_num=True, non_ascii=True, multiple_whitespaces=False, contractions=True,\n",
    "                                  currency_symbols=True) + \" \""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how how much you enjoyed this story reader writer and a programmer sharing concepts ideas and codes \n"
     ]
    }
   ],
   "source": [
    "print(cleaned_text[-100:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "with open(\"data/processed.txt\", \"w\") as file:\n",
    "    file.write(cleaned_text)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extracting Words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [],
   "source": [
    "path = \"data/processed.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "class WordExtractor:\n",
    "    \"\"\"\n",
    "    Read txt file and extract words with frequency.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.words = dict()\n",
    "\n",
    "    def extract_words(self, filename):\n",
    "        \"\"\"\n",
    "        extract words from filename\n",
    "        \"\"\"\n",
    "        with open(filename, \"r\") as file:\n",
    "            for line in file.readlines():\n",
    "                words = line.split()\n",
    "                for word in words:\n",
    "                    self.words[word] = 1 if word not in self.words else self.words[word] + 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "texts = WordExtractor()\n",
    "texts.extract_words(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "words = texts.words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "286225"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling Spell checker"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [],
   "source": [
    "class SpellingCheck:\n",
    "    \"\"\"\n",
    "    Check if the spelling is correct or incorrect\n",
    "    If incorrect with it will correct it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename=None):\n",
    "        \"\"\"\n",
    "        Pass the text file path for text extraction.\n",
    "        \"\"\"\n",
    "        self.words_frequency = dict()\n",
    "        self.filename = filename\n",
    "        self.total_words = 0\n",
    "        self.letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "    def extract_words(self, filename=None):\n",
    "        \"\"\"\n",
    "        extract words from filename\n",
    "        \"\"\"\n",
    "        if not filename and not self.filename:\n",
    "            return \"Please Enter text file path\"\n",
    "        if filename:\n",
    "            self.filename = filename\n",
    "        with open(self.filename, \"r\") as text_file:\n",
    "            for line in text_file.readlines():\n",
    "                line_words = line.split()\n",
    "                for word in line_words:\n",
    "                    if word not in self.words_frequency:\n",
    "                        self.words_frequency[word] = [1]\n",
    "                    else:\n",
    "                        self.words_frequency[word][0] += 1\n",
    "                    self.total_words += 1\n",
    "        self.__calculate_probability__()\n",
    "\n",
    "    def __calculate_probability__(self):\n",
    "        \"\"\"\n",
    "        Calculate probability when picking equally.\n",
    "        \"\"\"\n",
    "        for key, val in self.words_frequency.items():\n",
    "            if len(val) == 1:\n",
    "                self.words_frequency[key].append(val[0] / self.total_words)\n",
    "            else:\n",
    "                self.words_frequency[key][1] = val[0] / self.total_words  # incase used twice\n",
    "\n",
    "\n",
    "    def __missing__(self, word):\n",
    "        \"\"\"\n",
    "        Generate random words considering there's a missing letter in between.\n",
    "        \"\"\"\n",
    "        lists = []\n",
    "        for i in range(len(word)):\n",
    "            lists.append(word[:i] + word[i + 1:])\n",
    "        return lists\n",
    "\n",
    "    def __swapped__(self, word):\n",
    "        \"\"\"\n",
    "        Generate text swapping adjacent.\n",
    "        \"\"\"\n",
    "        lists = []\n",
    "        for i in range(len(word) - 1):\n",
    "            lists.append(word[:i] + word[i + 1] + word[i] + word[i + 2:])\n",
    "        return lists\n",
    "\n",
    "    def __miss_typed__(self, word):\n",
    "        \"\"\"\n",
    "        Generate word for missing a letter.\n",
    "        \"\"\"\n",
    "        lists = []\n",
    "        for i in range(len(word) + 1):\n",
    "            for j in self.letters:\n",
    "                lists.append(word[:i] + j + word[i + 1:])\n",
    "        return lists\n",
    "\n",
    "    def __extra_typed__(self, word):\n",
    "        \"\"\"\n",
    "        Generate word with an extra letter.\n",
    "        \"\"\"\n",
    "        lists = []\n",
    "        for i in range(len(word) + 1):\n",
    "            for j in self.letters:\n",
    "                lists.append(word[:i] + j + word[i:])\n",
    "        return lists\n",
    "\n",
    "    def __level_one_edits__(self, word):\n",
    "        \"\"\"\n",
    "        Generates sets of all the possible mistakes.\n",
    "        \"\"\"\n",
    "        return set(\n",
    "            self.__miss_typed__(word) + self.__missing__(word) + self.__extra_typed__(word) + self.__swapped__(word))\n",
    "\n",
    "    def __level_two_edits__(self, word):\n",
    "        \"\"\"\n",
    "        two level mistakes.\n",
    "        \"\"\"\n",
    "        return set(j for i in self.__level_one_edits__(word) for j in self.__level_one_edits__(i))\n",
    "\n",
    "    def possibility(self, word):\n",
    "        if word in self.words_frequency:\n",
    "            return word\n",
    "\n",
    "        pos = []\n",
    "        can_be = self.__level_two_edits__(word).union(self.__level_one_edits__(word))\n",
    "        for i in can_be:\n",
    "            if i in self.words_frequency:\n",
    "                pos.append((i, self.words_frequency[i][1]))\n",
    "        return pos\n",
    "\n",
    "    def edit_cost(self, word, predicted):\n",
    "        \"\"\"\n",
    "        Calculate editing cost for changing the letters\n",
    "        \"\"\"\n",
    "        n, m = len(word), len(predicted)\n",
    "        dp = [[1000] * (m + 1) for j in range(n + 1)]\n",
    "        for i in range(0, n + 1):\n",
    "            for j in range(0, m + 1):\n",
    "                if not i and not j:\n",
    "                    dp[i][j] = 0\n",
    "                elif not i:\n",
    "                    dp[i][j] = j\n",
    "                elif not j:\n",
    "                    dp[i][j] = i\n",
    "                else:\n",
    "                    if word[i - 1] == predicted[j - 1]:\n",
    "                        dp[i][j] = dp[i - 1][j - 1]\n",
    "                    else:\n",
    "                        dp[i][j] = min(dp[i - 1][j] + 3, dp[i - 1][j - 1] + 1,\n",
    "                                           dp[i][j - 1] + 2)\n",
    "        return dp[n][m]\n",
    "\n",
    "    def check_spell(self, word):\n",
    "        \"\"\"\n",
    "        Checks if the word is incorrect\n",
    "        \"\"\"\n",
    "        if word in self.words_frequency:\n",
    "            return word\n",
    "        pos = self.possibility(word)\n",
    "        corrected = \"\"\n",
    "        min_cost = 1000\n",
    "        prob = 0.0\n",
    "\n",
    "        for i in pos:\n",
    "            current_cost = self.edit_cost(word, i[0])\n",
    "            print(i)\n",
    "            if current_cost < min_cost:\n",
    "                corrected = i[0]\n",
    "                prob = i[1]\n",
    "            elif current_cost == min_cost and prob < i[1]:\n",
    "                prob = i[1]\n",
    "                corrected = i[0]\n",
    "        return corrected"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [],
   "source": [
    "test = SpellingCheck()\n",
    "test.extract_words(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('love', 0.0001789985842839243)\n",
      "('loves', 4.881779571379754e-06)\n",
      "('lover', 1.789985842839243e-05)\n",
      "('loved', 8.136299285632923e-06)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'loved'"
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.check_spell(\"lovvv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# END"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}