{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  label\n0  I grew up (b. 1965) watching and loving the Th...      0\n1  When I put this movie in my DVD player, and sa...      0\n2  Why do people who do not know what a particula...      0\n3  Even though I have great interest in Biblical ...      0\n4  Im a die hard Dads Army fan and nothing will e...      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I grew up (b. 1965) watching and loving the Th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When I put this movie in my DVD player, and sa...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do people who do not know what a particula...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Even though I have great interest in Biblical ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Im a die hard Dads Army fan and nothing will e...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data/train.csv\")\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    40000 non-null  object\n",
      " 1   label   40000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1], dtype=int64)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(40000, 2)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    X[\"text\"] = data[\"text\"].str.strip().str.lower()\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "x = data[\"text\"]\n",
    "y = data[\"label\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Vectorize text to numbers\n",
    "vec = CountVectorizer(stop_words=\"english\")\n",
    "x_train = vec.fit_transform(x_train).toarray()\n",
    "x_test = vec.transform(x_test).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": "MultinomialNB()"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "base_model = MultinomialNB()\n",
    "base_model.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "base_line = base_model.score(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.857"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_line"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part - 2 Naive Bayes From scratch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Note to myself - Either use C++ or look for any GPU library for text cleaning.\n",
    "class TextProcess:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.stem = PorterStemmer()\n",
    "        self.remove_punc = RegexpTokenizer(r\"\\w+\")\n",
    "        self.stop_words = set(stopwords.words(\"english\"))\n",
    "        self.data = data\n",
    "        self.labels = data[\"label\"]\n",
    "        self.x = []\n",
    "        self.specific = {\"br\"}\n",
    "\n",
    "    def __clean_text__(self):\n",
    "        for i in data[\"text\"]:\n",
    "            self.x.append(self.__clean__(i))\n",
    "\n",
    "    def __clean__(self, string):\n",
    "        text = list(self.remove_punc.tokenize(string.lower()))\n",
    "        processed_text = []\n",
    "        for i in text:\n",
    "            if i in self.stop_words and i != \"not\" or i in self.specific or i.isdigit():\n",
    "                continue\n",
    "            processed_text.append(self.stem.stem(i))\n",
    "        return processed_text\n",
    "\n",
    "    def get_data(self):\n",
    "        self.__clean_text__()\n",
    "        return self.x, self.labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "cleaned = TextProcess(data)\n",
    "x, y = cleaned.get_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grew', 'b', 'watch', 'love', 'thunderbird', 'mate', 'school', 'watch', 'play', 'thunderbird', 'school', 'lunch', 'school', 'want', 'virgil', 'scott', 'one', 'want', 'alan', 'count', 'becam', 'art', 'form', 'took', 'children', 'see', 'movi', 'hope', 'would', 'get', 'glimps', 'love', 'child', 'bitterli', 'disappoint', 'high', 'point', 'snappi', 'theme', 'tune', 'not', 'could', 'compar', 'origin', 'score', 'thunderbird', 'thank', 'earli', 'saturday', 'morn', 'one', 'televis', 'channel', 'still', 'play', 'rerun', 'seri', 'gerri', 'anderson', 'wife', 'creat', 'jonatha', 'frake', 'hand', 'director', 'chair', 'version', 'complet', 'hopeless', 'wast', 'film', 'utter', 'rubbish', 'cgi', 'remak', 'may', 'accept', 'replac', 'marionett', 'homo', 'sapien', 'subsp', 'sapien', 'huge', 'error', 'judgment']\n"
     ]
    }
   ],
   "source": [
    "print(x[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Note to myself - Optimize this with CUDA.\n",
    "\n",
    "class Model:\n",
    "    \"\"\"\n",
    "    Extract freq for pos, neg separately.\n",
    "    count unique words, neg words, pos words.\n",
    "    Calculate laplacian smoothing.\n",
    "    Calculate log prior, log likelihood\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.pos, self.neg = {}, {}\n",
    "        self.unique = 0.0\n",
    "        self.pos_val, self.neg_val = 0.0, 0.0\n",
    "        self.prior = None\n",
    "        self.sen = None\n",
    "        self.labels = None\n",
    "\n",
    "    def build(self, sen, labels):\n",
    "        self.sen = sen\n",
    "        self.labels = labels\n",
    "        for i, texts in enumerate(sen):\n",
    "            for j in texts:\n",
    "                if labels[i] == 1:\n",
    "                    if j not in self.pos:\n",
    "                        self.pos[j] = 1\n",
    "                        self.pos_val += 1\n",
    "                        self.unique += 1\n",
    "                    else:\n",
    "                        self.pos[j] += 1\n",
    "                if labels[i] == 0:\n",
    "                    if j not in self.neg:\n",
    "                        self.neg[j] = 1\n",
    "                        self.neg_val += 1\n",
    "                        self.unique += 1\n",
    "                    else:\n",
    "                        self.neg[j] += 1\n",
    "        self.prior = self.pos_val / self.neg_val\n",
    "        print(\"Build Complete (prior value: {})\".format(self.prior))\n",
    "\n",
    "    def laplacian_smoothing(self, val, n_class, total):\n",
    "        return (val + 1) / (n_class + total)\n",
    "\n",
    "    def calculate_lambda(self, text):\n",
    "        val = 0.0\n",
    "        for i in text:\n",
    "            up = self.pos[i] if i in self.pos else 0\n",
    "            down = self.neg[i] if i in self.neg else 0\n",
    "            up = self.laplacian_smoothing(up, self.pos_val, self.unique)\n",
    "            down = self.laplacian_smoothing(down, self.neg_val, self.unique)\n",
    "            val = np.log(val) + np.log(up / down)\n",
    "        return val + self.prior\n",
    "\n",
    "\n",
    "    def predict(self, sentences, labels):\n",
    "        predict_labels = []\n",
    "        for i in sentences:\n",
    "            val = self.calculate_lambda(i)\n",
    "            if val > 0:\n",
    "                predict_labels.append(1)\n",
    "            else:\n",
    "                predict_labels.append(0)\n",
    "        res = 0\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == predict_labels[i]:\n",
    "                res += 1\n",
    "        return res / len(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Complete (prior value: 1.046548885229852)\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "model_1 = Model()\n",
    "model_1.build(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = model_1.predict(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500475\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3 - Implementing Deep Learning Model (BERT) without Transfer learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}